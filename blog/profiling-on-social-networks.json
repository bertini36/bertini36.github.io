{"title":"Profiling on social networks","slug":"profiling-on-social-networks","tags":["#python","#twitter","#text-mining","#machine-learning","#lda"],"date":"2019-06-22","html":"\n<div class=\"content\">\n\t<p class=\"post_p\">\n\t\tLast weekend I was coding an application for Twitter timelines analysis which I called\n\t\t<a href=\"https://github.com/bertini36/profiler\" class=\"post_link\" target=\"_blank\">Profiler</a> (I was just bored). Some years ago I\n\t\twas working on probabilistic models and there was one which got my attention:\n\t\t<a href=\"http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf\" class=\"post_link\" target=\"_blank\">Latent Dirichlet Allocation</a>.\n\t</p>\n\t<p class=\"post_p\">\n\t\tThis model was developed by David Blei, Andrew Ng y Michael I. Jordan and tries to find topics in document collections.\n\t\tIn other words, it groups text documents into topics that the model itself discovers. In this post I'm not going\n\t\tto explain the model structure and its inference, for this what better than to read the\n\t\t<a href=\"http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf\" class=\"post_link\" target=\"_blank\">paper</a> itself.\n\t</p>\n\t<p class=\"post_p\">\n\t\tThis model is based on estimating  <a href=\"https://en.wikipedia.org/wiki/Dirichlet_distribution\" class=\"post_link\" target=\"_blank\">\n\t\tDirichlet distributions</a>. This kind of distributions model the probability of membership to a set of classes.\n\t\tSpecifically the model builds (using an iterative procedure) Dirichlet distributions to model the\n\t\tprobability of a word referring to a concrete topic and the probability of membership from each document to\n\t\teach of the topics. The parameters estimation of these distributions can be done using different types of\n\t\tBayesian inference like <a href=\"https://albertopou.herokuapp.com/#variational_inference_1\" class=\"post_link\" target=\"_blank\">Variational Inference</a>\n\t\tor sampling methods as <a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\" class=\"post_link\" target=\"_blank\">Markov Chain Monte Carlo</a>.\n\t</p>\n\t<p class=\"post_p\">\n\t\tProfiler uses this probabilistic model to identify, given a Twitter timeline (set of user tweets), several\n\t\ttopics that this user writes about. From this idea I coded a Python application that downloads all these tweets of\n\t\ta user, stores them, preprocesses them and finally looks for its main topics.\n\t</p>\n\t<h4 class=\"post_section_title text-2xl text-black\">Technological stack</h4>\n\t<ul class=\"post_list\">\n\t\t<li>\n\t\t\tTwitter data is downloaded using <a href=\"https://github.com/tweepy/tweepy\" class=\"post_link\" target=\"_blank\">Tweepy</a>.\n\t\t</li>\n\t\t<li>\n\t\t\tTo store the timelines I used a <a href=\"https://www.mongodb.com/\" class=\"post_link\" target=\"_blank\">MongoDB</a> database with\n\t\t\twhich I interacted using <a href=\"https://github.com/mongodb/mongo-python-driver\" class=\"post_link\" target=\"_blank\">Pymongo</a>.\n\t\t</li>\n\t\t<li>\n\t\t\tTextual data preprocessing was done using libraries as  <a href=\"https://github.com/pandas-dev/pandas\" class=\"post_link\" target=\"_blank\">Pandas</a>\n\t\t\tand <a href=\"https://github.com/nltk/nltk\" class=\"post_link\" target=\"_blank\">NLTK</a>. This preprocessing consisted on cleaning\n\t\t\ttweets to avoid deviations (delete emoticons, capital letters, symbols, digits, ...)\n\t\t</li>\n\t\t<li>\n\t\t\tTo infer the model I used  <a href=\"https://github.com/RaRe-Technologies/gensim\" class=\"post_link\" target=\"_blank\">Gensim</a>\n\t\t\tlibrary. This library has a concurrent LDA implementation.\n\t\t</li>\n\t\t<li>\n\t\t\tTo plot obtained results I used <a href=\"https://github.com/bmabey/pyLDAvis\" class=\"post_link\" target=\"_blank\">pyLDAvis</a>\n\t\t\tlibrary which generates interactive HTML that avoids to explore the results and check which words\n\t\t\tare the most important in each topic.\n\t\t</li>\n\t\t<li>\n\t\t\tI coded also a command interface to ease interact with the library. To do this I used Google\n\t\t\t<a href=\"https://github.com/google/python-fire\" class=\"post_link\" target=\"_blank\">Fire</a> library.\n\t\t</li>\n\t\t<li>\n\t\t\tI configured the development environment using\n\t\t\t<a href=\"https://www.docker.com/\" class=\"post_link\" target=\"_blank\">Docker</a>,\n\t\t\t<a href=\"https://docs.docker.com/compose/\" class=\"post_link\" target=\"_blank\">Docker compose</a> and\n\t\t\t<a href=\"https://travis-ci.org/\" class=\"post_link\" target=\"_blank\">Travis</a> to execute automatic tests.\n\t\t</li>\n\t</ul>\n\t<h4 class=\"post_section_title text-2xl text-black\">Command interface</h4>\n\t<p class=\"post_p\">\n\t\tProfiler has a command interface. With the next command you could analize some Spain politicians:\n\t</p>\n\t<div class=\"post_code\">\n\t\t<pre><code>make run_all timelines=Albert_Rivera,sanchezcastejon,Pablo_Iglesias_,pablocasado_ n_topics=5</code></pre>\n\t</div>\n\t<p class=\"post_p\">\n\t\tYou can find Profiler installation steps at the\n\t\t<a href=\"https://github.com/bertini36/profiler/blob/master/README.md\" class=\"post_link\" target=\"_blank\">repository</a>.\n\t\tIn this <a href=\"https://github.com/bertini36/profiler/blob/master/src/settings.py\" class=\"post_link\" target=\"_blank\">file</a> you\n\t\tcan configure some application behaviours about the data preprocessing and about the model.\n\t</p>\n\t<h4 class=\"post_section_title text-2xl text-black\">Example of obtained results</h4>\n\t<div class=\"post_image_div md:px-40\">\n\t\t<figure>\n\t\t\t<img class=\"post_image\" src=\"profiling-on-social-networks/profiler1.png\" alt=\"Results\">\n\t\t\t<figcaption class=\"post_image_figcaption\">\n\t\t\t\tGroup 1\n\t\t\t</figcaption>\n\t\t</figure>\n\t</div>\n\t<div class=\"post_image_div md:px-40\">\n\t\t<figure>\n\t\t\t<img class=\"post_image\" src=\"profiling-on-social-networks/profiler2.png\" alt=\"Results\">\n\t\t\t<figcaption class=\"post_image_figcaption\">\n\t\t\t\tGroup 4\n\t\t\t</figcaption>\n\t\t</figure>\n\t</div>\n\t<p class=\"post_p mb-10\">\n\t\tObtained results using tweets are not as good as obtained using posts or article news. This is because tweets\n\t\tare short text documents. This reduced length causes a much smaller vocabulary and therefore a difficulty\n\t\tfor the model to identify differentiated topics. However in this example we can see some interesting groups.\n\t\tThese results are from Pedro SÃ¡nchez timeline (president of Spain). At group 1 we could see that it refers to\n\t\ttweets about last campaign and at group 4 we see that refers to the issue of sexist violence.\n\t</p>\n</div>\n\t\t"}