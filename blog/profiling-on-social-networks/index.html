<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet> <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest crossorigin=use-credentials> <link href=black_logo.png rel=icon type=image/png> <link href=client/main.419280361.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>Profiling on social networks ü§π‚Äç‚ôÇÔ∏è</title><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <nav class="svelte-71l2nh border-b-2 font-light px-4 py-0"><ul class="svelte-71l2nh m-0 p-0"><li class=float-left><a class="block hover:text-red-500 no-underline px-3 py-4 svelte-71l2nh" href=.>Home</a></li> <li class=float-left><a class="block hover:text-red-500 no-underline px-3 py-4 svelte-71l2nh" href=blog aria-current=page rel=prefetch>Blog</a></li> <li class=float-right><a class="block hover:text-red-500 no-underline px-3 py-4 text-black" href=https://github.com/bertini36/blogv2 target=_blank><i class="fa fa-github"></i></a></ul></nav> <main class=svelte-1uhnsl8> <h1 class=text-4xl>Profiling on social networks ü§π‚Äç‚ôÇÔ∏è</h1> <div class="mb-10 content svelte-1lhkq7r"> <p class=post_p> Last weekend I was coding an application for Twitter timelines analysis which I called <a class=post_link href=https://github.com/bertini36/profiler target=_blank>Profiler</a> (I was just bored). Some years ago I was working on probabilistic models and there was one which got my attention: <a class=post_link href=http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf target=_blank>Latent Dirichlet Allocation</a>. </p> <p class=post_p> This model was developed by David Blei, Andrew Ng y Michael I. Jordan and tries to find topics in document collections. In other words, it groups text documents into topics that the model itself discovers. In this post I'm not going to explain the model structure and its inference, for this what better than to read the <a class=post_link href=http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf target=_blank>paper</a> itself. </p> <p class=post_p> This model is based on estimating <a class=post_link href=https://en.wikipedia.org/wiki/Dirichlet_distribution target=_blank> Dirichlet distributions</a>. This kind of distributions model the probability of membership to a set of classes. Specifically the model builds (using an iterative procedure) Dirichlet distributions to model the probability of a word referring to a concrete topic and the probability of membership from each document to each of the topics. The parameters estimation of these distributions can be done using different types of Bayesian inference like <a class=post_link href=https://albertopou.herokuapp.com/#variational_inference_1 target=_blank>Variational Inference</a> or sampling methods as <a class=post_link href=https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo target=_blank>Markov Chain Monte Carlo</a>. </p> <p class=post_p> Profiler uses this probabilistic model to identify, given a Twitter timeline (set of user tweets), several topics that this user writes about. From this idea I coded a Python application that downloads all these tweets of a user, stores them, preprocesses them and finally looks for its main topics. </p> <h4 class="text-black text-2xl post_section_title">Technological stack</h4> <ul class=post_list> <li> Twitter data is downloaded using <a class=post_link href=https://github.com/tweepy/tweepy target=_blank>Tweepy</a>. </li> <li> To store the timelines I used a <a class=post_link href=https://www.mongodb.com/ target=_blank>MongoDB</a> database with which I interacted using <a class=post_link href=https://github.com/mongodb/mongo-python-driver target=_blank>Pymongo</a>. </li> <li> Textual data preprocessing was done using libraries as <a class=post_link href=https://github.com/pandas-dev/pandas target=_blank>Pandas</a> and <a class=post_link href=https://github.com/nltk/nltk target=_blank>NLTK</a>. This preprocessing consisted on cleaning tweets to avoid deviations (delete emoticons, capital letters, symbols, digits, ...) </li> <li> To infer the model I used <a class=post_link href=https://github.com/RaRe-Technologies/gensim target=_blank>Gensim</a> library. This library has a concurrent LDA implementation. </li> <li> To plot obtained results I used <a class=post_link href=https://github.com/bmabey/pyLDAvis target=_blank>pyLDAvis</a> library which generates interactive HTML that avoids to explore the results and check which words are the most important in each topic. </li> <li> I coded also a command interface to ease interact with the library. To do this I used Google <a class=post_link href=https://github.com/google/python-fire target=_blank>Fire</a> library. </li> <li> I configured the development environment using <a class=post_link href=https://www.docker.com/ target=_blank>Docker</a>, <a class=post_link href=https://docs.docker.com/compose/ target=_blank>Docker compose</a> and <a class=post_link href=https://travis-ci.org/ target=_blank>Travis</a> to execute automatic tests. </li> </ul> <h4 class="text-black text-2xl post_section_title">Command interface</h4> <p class=post_p> Profiler has a command interface. With the next command you could analize some Spain politicians: </p> <div class=post_code> <pre><code>make run_all timelines=Albert_Rivera,sanchezcastejon,Pablo_Iglesias_,pablocasado_ n_topics=5</code></pre> </div> <p class=post_p> You can find Profiler installation steps at the <a class=post_link href=https://github.com/bertini36/profiler/blob/master/README.md target=_blank>repository</a>. In this <a class=post_link href=https://github.com/bertini36/profiler/blob/master/src/settings.py target=_blank>file</a> you can configure some application behaviours about the data preprocessing and about the model. </p> <h4 class="text-black text-2xl post_section_title">Example of obtained results</h4> <figure class="flex justify-center post_figure"> <img alt=Results class=md:w-3/4 src=profiling-on-social-networks/profiler1.png> </figure> <figcaption class=post_image_figcaption> Group 1 </figcaption> <figure class="flex justify-center post_figure"> <img alt=Results class=md:w-3/4 src=profiling-on-social-networks/profiler2.png> </figure> <figcaption class=post_image_figcaption> Group 4 </figcaption> <p class=post_p> Obtained results using tweets are not as good as obtained using posts or article news. This is because tweets are short text documents. This reduced length causes a much smaller vocabulary and therefore a difficulty for the model to identify differentiated topics. However in this example we can see some interesting groups. These results are from Pedro S√°nchez timeline (president of Spain). At group 1 we could see that it refers to tweets about last campaign and at group 4 we see that refers to the issue of sexist violence. </p> <div class="border-red-400 border-t-2 my-10"></div> <div><h4 class="text-black text-2xl mb-10 text-center">Write a comment! üòÄ</h4> <figure class="flex justify-center"><img alt=Loader class=w-48 src=loader.gif></figure> <form class="w-full mt-16" onsubmit="return false"><div class="flex -mx-3 flex-wrap mb-6"><div class="w-full px-3 md:w-1/2 mb-6 md:mb-0"><label class="block text-gray-700 font-bold mb-2 text-xs tracking-wide uppercase" for=name>Name</label> <input class="block text-gray-700 appearance-none bg-gray-200 border border-gray-200 focus:bg-white focus:border-gray-500 focus:outline-none leading-tight px-4 py-3 rounded w-full"> <p class="text-xs text-red-600"></div> <div class="w-full px-3 md:w-1/2"><label class="block text-gray-700 font-bold mb-2 text-xs tracking-wide uppercase" for=email>Email</label> <input class="block text-gray-700 appearance-none bg-gray-200 border border-gray-200 focus:bg-white focus:border-gray-500 focus:outline-none leading-tight px-4 py-3 rounded w-full"> <p class="text-xs text-red-600"></div></div> <div class="flex -mx-3 flex-wrap mb-6"><div class="w-full px-3"><label class="block text-gray-700 font-bold mb-2 text-xs tracking-wide uppercase" for=comment>Comment</label> <textarea class="block text-gray-700 appearance-none bg-gray-200 border border-gray-200 focus:bg-white focus:border-gray-500 focus:outline-none leading-tight px-4 py-3 rounded w-full" rows=2></textarea> <p class="text-xs text-red-600"></div></div> <div class=w-full><button class="w-full px-4 rounded bg-red-500 border-b-4 border-red-700 font-bold hover:bg-red-400 hover:border-red-500 py-2 text-white">Send </button></div></form></div></div></main></div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,{post:{title:"Profiling on social networks ü§π‚Äç‚ôÇÔ∏è",slug:"profiling-on-social-networks",tags:["#python","#twitter","#text-mining","#machine-learning","#lda"],date:"2019-06-22",html:"\n\u003Cp class=\"post_p\"\u003E\n\tLast weekend I was coding an application for Twitter timelines analysis which I called\n\t\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbertini36\u002Fprofiler\" class=\"post_link\" target=\"_blank\"\u003EProfiler\u003C\u002Fa\u003E (I was just bored). Some years ago I\n\twas working on probabilistic models and there was one which got my attention:\n\t\u003Ca href=\"http:\u002F\u002Fwww.jmlr.org\u002Fpapers\u002Fvolume3\u002Fblei03a\u002Fblei03a.pdf\" class=\"post_link\" target=\"_blank\"\u003ELatent Dirichlet Allocation\u003C\u002Fa\u003E.\n\u003C\u002Fp\u003E\n\u003Cp class=\"post_p\"\u003E\n\tThis model was developed by David Blei, Andrew Ng y Michael I. Jordan and tries to find topics in document collections.\n\tIn other words, it groups text documents into topics that the model itself discovers. In this post I'm not going\n\tto explain the model structure and its inference, for this what better than to read the\n\t\u003Ca href=\"http:\u002F\u002Fwww.jmlr.org\u002Fpapers\u002Fvolume3\u002Fblei03a\u002Fblei03a.pdf\" class=\"post_link\" target=\"_blank\"\u003Epaper\u003C\u002Fa\u003E itself.\n\u003C\u002Fp\u003E\n\u003Cp class=\"post_p\"\u003E\n\tThis model is based on estimating  \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FDirichlet_distribution\" class=\"post_link\" target=\"_blank\"\u003E\n\tDirichlet distributions\u003C\u002Fa\u003E. This kind of distributions model the probability of membership to a set of classes.\n\tSpecifically the model builds (using an iterative procedure) Dirichlet distributions to model the\n\tprobability of a word referring to a concrete topic and the probability of membership from each document to\n\teach of the topics. The parameters estimation of these distributions can be done using different types of\n\tBayesian inference like \u003Ca href=\"https:\u002F\u002Falbertopou.herokuapp.com\u002F#variational_inference_1\" class=\"post_link\" target=\"_blank\"\u003EVariational Inference\u003C\u002Fa\u003E\n\tor sampling methods as \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMarkov_chain_Monte_Carlo\" class=\"post_link\" target=\"_blank\"\u003EMarkov Chain Monte Carlo\u003C\u002Fa\u003E.\n\u003C\u002Fp\u003E\n\u003Cp class=\"post_p\"\u003E\n\tProfiler uses this probabilistic model to identify, given a Twitter timeline (set of user tweets), several\n\ttopics that this user writes about. From this idea I coded a Python application that downloads all these tweets of\n\ta user, stores them, preprocesses them and finally looks for its main topics.\n\u003C\u002Fp\u003E\n\u003Ch4 class=\"post_section_title text-2xl text-black\"\u003ETechnological stack\u003C\u002Fh4\u003E\n\u003Cul class=\"post_list\"\u003E\n\t\u003Cli\u003E\n\t\tTwitter data is downloaded using \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ftweepy\u002Ftweepy\" class=\"post_link\" target=\"_blank\"\u003ETweepy\u003C\u002Fa\u003E.\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tTo store the timelines I used a \u003Ca href=\"https:\u002F\u002Fwww.mongodb.com\u002F\" class=\"post_link\" target=\"_blank\"\u003EMongoDB\u003C\u002Fa\u003E database with\n\t\twhich I interacted using \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmongodb\u002Fmongo-python-driver\" class=\"post_link\" target=\"_blank\"\u003EPymongo\u003C\u002Fa\u003E.\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tTextual data preprocessing was done using libraries as  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpandas-dev\u002Fpandas\" class=\"post_link\" target=\"_blank\"\u003EPandas\u003C\u002Fa\u003E\n\t\tand \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fnltk\u002Fnltk\" class=\"post_link\" target=\"_blank\"\u003ENLTK\u003C\u002Fa\u003E. This preprocessing consisted on cleaning\n\t\ttweets to avoid deviations (delete emoticons, capital letters, symbols, digits, ...)\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tTo infer the model I used  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FRaRe-Technologies\u002Fgensim\" class=\"post_link\" target=\"_blank\"\u003EGensim\u003C\u002Fa\u003E\n\t\tlibrary. This library has a concurrent LDA implementation.\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tTo plot obtained results I used \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbmabey\u002FpyLDAvis\" class=\"post_link\" target=\"_blank\"\u003EpyLDAvis\u003C\u002Fa\u003E\n\t\tlibrary which generates interactive HTML that avoids to explore the results and check which words\n\t\tare the most important in each topic.\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tI coded also a command interface to ease interact with the library. To do this I used Google\n\t\t\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fgoogle\u002Fpython-fire\" class=\"post_link\" target=\"_blank\"\u003EFire\u003C\u002Fa\u003E library.\n\t\u003C\u002Fli\u003E\n\t\u003Cli\u003E\n\t\tI configured the development environment using\n\t\t\u003Ca href=\"https:\u002F\u002Fwww.docker.com\u002F\" class=\"post_link\" target=\"_blank\"\u003EDocker\u003C\u002Fa\u003E,\n\t\t\u003Ca href=\"https:\u002F\u002Fdocs.docker.com\u002Fcompose\u002F\" class=\"post_link\" target=\"_blank\"\u003EDocker compose\u003C\u002Fa\u003E and\n\t\t\u003Ca href=\"https:\u002F\u002Ftravis-ci.org\u002F\" class=\"post_link\" target=\"_blank\"\u003ETravis\u003C\u002Fa\u003E to execute automatic tests.\n\t\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch4 class=\"post_section_title text-2xl text-black\"\u003ECommand interface\u003C\u002Fh4\u003E\n\u003Cp class=\"post_p\"\u003E\n\tProfiler has a command interface. With the next command you could analize some Spain politicians:\n\u003C\u002Fp\u003E\n\u003Cdiv class=\"post_code\"\u003E\n\t\u003Cpre\u003E\u003Ccode\u003Emake run_all timelines=Albert_Rivera,sanchezcastejon,Pablo_Iglesias_,pablocasado_ n_topics=5\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003C\u002Fdiv\u003E\n\u003Cp class=\"post_p\"\u003E\n\tYou can find Profiler installation steps at the\n\t\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbertini36\u002Fprofiler\u002Fblob\u002Fmaster\u002FREADME.md\" class=\"post_link\" target=\"_blank\"\u003Erepository\u003C\u002Fa\u003E.\n\tIn this \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbertini36\u002Fprofiler\u002Fblob\u002Fmaster\u002Fsrc\u002Fsettings.py\" class=\"post_link\" target=\"_blank\"\u003Efile\u003C\u002Fa\u003E you\n\tcan configure some application behaviours about the data preprocessing and about the model.\n\u003C\u002Fp\u003E\n\u003Ch4 class=\"post_section_title text-2xl text-black\"\u003EExample of obtained results\u003C\u002Fh4\u003E\n\u003Cfigure class=\"post_figure flex justify-center\"\u003E\n\t\u003Cimg class=\"md:w-3\u002F4\" src=\"profiling-on-social-networks\u002Fprofiler1.png\" alt=\"Results\"\u003E\n\u003C\u002Ffigure\u003E\n\u003Cfigcaption class=\"post_image_figcaption\"\u003E\n\tGroup 1\n\u003C\u002Ffigcaption\u003E\n\u003Cfigure class=\"post_figure flex justify-center\"\u003E\n\t\u003Cimg class=\"md:w-3\u002F4\" src=\"profiling-on-social-networks\u002Fprofiler2.png\" alt=\"Results\"\u003E\n\u003C\u002Ffigure\u003E\n\u003Cfigcaption class=\"post_image_figcaption\"\u003E\n\tGroup 4\n\u003C\u002Ffigcaption\u003E\n\u003Cp class=\"post_p\"\u003E\n\tObtained results using tweets are not as good as obtained using posts or article news. This is because tweets\n\tare short text documents. This reduced length causes a much smaller vocabulary and therefore a difficulty\n\tfor the model to identify differentiated topics. However in this example we can see some interesting groups.\n\tThese results are from Pedro S√°nchez timeline (president of Spain). At group 1 we could see that it refers to\n\ttweets about last campaign and at group 4 we see that refers to the issue of sexist violence.\n\u003C\u002Fp\u003E\n\t\t"},comments_url:"https:\u002F\u002Fxjdf38glwl.execute-api.eu-west-1.amazonaws.com\u002Fprod\u002Fcomments\u002Fprofiling-on-social-networks"}]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.fdb076c1.js"}catch(e){main="/client/legacy/client.8bac5623.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 